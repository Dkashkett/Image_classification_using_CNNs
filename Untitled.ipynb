{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data chunks and converts to numpy arrays\n",
    "def load_pose_data():\n",
    "    pose = np.array(loadmat('./data/pose.mat')['pose'])\n",
    "    illum = np.array(loadmat('./data/illumination.mat')['illum'])\n",
    "    return pose, illum\n",
    "\n",
    "def make_pose_dataset(pose, illum, test_size = .3):\n",
    "    pose_data = []\n",
    "    pose_labels = []\n",
    "    for subject in range(68):\n",
    "        for img in range(13):\n",
    "            pose_data.append(pose[:,:,img,subject])\n",
    "            pose_labels.append(subject)\n",
    "            \n",
    "    pose_data = np.array(pose_data)\n",
    "    pose_labels = np.transpose(np.array(pose_labels))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(pose_data, pose_labels, test_size=test_size, random_state=31, stratify=pose_labels)\n",
    "    X_train, y_train = list(X_train), list(y_train)\n",
    "    \n",
    "    for subject in range(68):\n",
    "        for img in range(21):\n",
    "            image = illum[:,img,subject].reshape((40,48))\n",
    "            image = np.flip(np.rot90(image))\n",
    "            X_train.append(image)\n",
    "            y_train.append(subject)\n",
    "            \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networks\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(68, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2046, 48, 40)\n",
      "(266, 48, 40)\n"
     ]
    }
   ],
   "source": [
    "#load pose data\n",
    "pose, illum = load_pose_data()\n",
    "X_train, X_test, y_train, y_test = make_pose_dataset(pose, illum)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view mnist data\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model_func, X_train, X_test, y_train, y_test):\n",
    "    # flatten 28*28 images to a 784 vector for each image\n",
    "    num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "    X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "    X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "    # normalize inputs from 0-255 to 0-1\n",
    "    X_train = X_train / 255\n",
    "    X_test = X_test / 255\n",
    "    # one hot encode outputs\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE SEQUENTIAL MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 - 0s - loss: 6.0885 - accuracy: 0.0303 - val_loss: 5.5838 - val_accuracy: 0.0639\n",
      "Epoch 2/30\n",
      "11/11 - 0s - loss: 4.5637 - accuracy: 0.0997 - val_loss: 4.4083 - val_accuracy: 0.1165\n",
      "Epoch 3/30\n",
      "11/11 - 0s - loss: 3.6721 - accuracy: 0.2468 - val_loss: 3.6986 - val_accuracy: 0.1128\n",
      "Epoch 4/30\n",
      "11/11 - 0s - loss: 2.9724 - accuracy: 0.4184 - val_loss: 3.3135 - val_accuracy: 0.1353\n",
      "Epoch 5/30\n",
      "11/11 - 0s - loss: 2.5837 - accuracy: 0.5093 - val_loss: 3.1724 - val_accuracy: 0.1955\n",
      "Epoch 6/30\n",
      "11/11 - 0s - loss: 2.1959 - accuracy: 0.5826 - val_loss: 2.9756 - val_accuracy: 0.2820\n",
      "Epoch 7/30\n",
      "11/11 - 0s - loss: 1.9002 - accuracy: 0.6676 - val_loss: 2.6465 - val_accuracy: 0.3195\n",
      "Epoch 8/30\n",
      "11/11 - 0s - loss: 1.6202 - accuracy: 0.7341 - val_loss: 2.6000 - val_accuracy: 0.3534\n",
      "Epoch 9/30\n",
      "11/11 - 0s - loss: 1.3982 - accuracy: 0.7996 - val_loss: 2.5189 - val_accuracy: 0.4023\n",
      "Epoch 10/30\n",
      "11/11 - 0s - loss: 1.2178 - accuracy: 0.8314 - val_loss: 2.3276 - val_accuracy: 0.4436\n",
      "Epoch 11/30\n",
      "11/11 - 0s - loss: 1.0758 - accuracy: 0.8446 - val_loss: 2.1241 - val_accuracy: 0.4962\n",
      "Epoch 12/30\n",
      "11/11 - 0s - loss: 0.9440 - accuracy: 0.8759 - val_loss: 2.1653 - val_accuracy: 0.4286\n",
      "Epoch 13/30\n",
      "11/11 - 0s - loss: 0.8322 - accuracy: 0.8856 - val_loss: 1.8517 - val_accuracy: 0.5789\n",
      "Epoch 14/30\n",
      "11/11 - 0s - loss: 0.7218 - accuracy: 0.9140 - val_loss: 1.8233 - val_accuracy: 0.5489\n",
      "Epoch 15/30\n",
      "11/11 - 0s - loss: 0.6400 - accuracy: 0.9345 - val_loss: 1.7367 - val_accuracy: 0.5977\n",
      "Epoch 16/30\n",
      "11/11 - 0s - loss: 0.5556 - accuracy: 0.9457 - val_loss: 1.6498 - val_accuracy: 0.6353\n",
      "Epoch 17/30\n",
      "11/11 - 0s - loss: 0.5369 - accuracy: 0.9433 - val_loss: 1.6926 - val_accuracy: 0.6128\n",
      "Epoch 18/30\n",
      "11/11 - 0s - loss: 0.4590 - accuracy: 0.9565 - val_loss: 1.6023 - val_accuracy: 0.6353\n",
      "Epoch 19/30\n",
      "11/11 - 0s - loss: 0.4052 - accuracy: 0.9668 - val_loss: 1.5170 - val_accuracy: 0.6729\n",
      "Epoch 20/30\n",
      "11/11 - 0s - loss: 0.3727 - accuracy: 0.9682 - val_loss: 1.5133 - val_accuracy: 0.6353\n",
      "Epoch 21/30\n",
      "11/11 - 0s - loss: 0.3489 - accuracy: 0.9648 - val_loss: 1.4681 - val_accuracy: 0.6617\n",
      "Epoch 22/30\n",
      "11/11 - 0s - loss: 0.3076 - accuracy: 0.9751 - val_loss: 1.4091 - val_accuracy: 0.6842\n",
      "Epoch 23/30\n",
      "11/11 - 0s - loss: 0.2758 - accuracy: 0.9819 - val_loss: 1.4672 - val_accuracy: 0.6617\n",
      "Epoch 24/30\n",
      "11/11 - 0s - loss: 0.2689 - accuracy: 0.9780 - val_loss: 1.3542 - val_accuracy: 0.7143\n",
      "Epoch 25/30\n",
      "11/11 - 0s - loss: 0.2722 - accuracy: 0.9726 - val_loss: 1.2717 - val_accuracy: 0.7293\n",
      "Epoch 26/30\n",
      "11/11 - 0s - loss: 0.2269 - accuracy: 0.9819 - val_loss: 1.3519 - val_accuracy: 0.6992\n",
      "Epoch 27/30\n",
      "11/11 - 0s - loss: 0.2015 - accuracy: 0.9863 - val_loss: 1.2663 - val_accuracy: 0.7293\n",
      "Epoch 28/30\n",
      "11/11 - 0s - loss: 0.1845 - accuracy: 0.9883 - val_loss: 1.2701 - val_accuracy: 0.7331\n",
      "Epoch 29/30\n",
      "11/11 - 0s - loss: 0.1675 - accuracy: 0.9932 - val_loss: 1.2432 - val_accuracy: 0.7444\n",
      "Epoch 30/30\n",
      "11/11 - 0s - loss: 0.1438 - accuracy: 0.9946 - val_loss: 1.2353 - val_accuracy: 0.7444\n",
      "Baseline Error: 25.56%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 4.2188 - accuracy: 0.0293 - val_loss: 4.1648 - val_accuracy: 0.0263\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 4.0392 - accuracy: 0.0978 - val_loss: 4.0001 - val_accuracy: 0.0677\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 3.7302 - accuracy: 0.2063 - val_loss: 3.7569 - val_accuracy: 0.1053\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 3.2887 - accuracy: 0.3104 - val_loss: 3.3959 - val_accuracy: 0.2218\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 2.7501 - accuracy: 0.4433 - val_loss: 3.0695 - val_accuracy: 0.2105\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 2.2174 - accuracy: 0.5782 - val_loss: 2.7555 - val_accuracy: 0.2556\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 1.7455 - accuracy: 0.6833 - val_loss: 2.4510 - val_accuracy: 0.3872\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 1.3621 - accuracy: 0.7654 - val_loss: 2.2528 - val_accuracy: 0.4361\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 1.0976 - accuracy: 0.8260 - val_loss: 1.9337 - val_accuracy: 0.5301\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.8368 - accuracy: 0.8798 - val_loss: 1.8336 - val_accuracy: 0.5752\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.7069 - accuracy: 0.8925 - val_loss: 1.7237 - val_accuracy: 0.5714\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.6174 - accuracy: 0.8988 - val_loss: 1.5626 - val_accuracy: 0.5940\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.5116 - accuracy: 0.9242 - val_loss: 1.6001 - val_accuracy: 0.5752\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.4262 - accuracy: 0.9394 - val_loss: 1.4793 - val_accuracy: 0.6541\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.3484 - accuracy: 0.9477 - val_loss: 1.4274 - val_accuracy: 0.6692\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.3476 - accuracy: 0.9433 - val_loss: 1.4089 - val_accuracy: 0.6917\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.2850 - accuracy: 0.9531 - val_loss: 1.3092 - val_accuracy: 0.6541\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.2609 - accuracy: 0.9565 - val_loss: 1.3971 - val_accuracy: 0.6391\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.2205 - accuracy: 0.9692 - val_loss: 1.3558 - val_accuracy: 0.6842\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1776 - accuracy: 0.9804 - val_loss: 1.2043 - val_accuracy: 0.6955\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.1605 - accuracy: 0.9844 - val_loss: 1.2696 - val_accuracy: 0.6955\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 0.1393 - accuracy: 0.9863 - val_loss: 1.1877 - val_accuracy: 0.7256\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.1172 - accuracy: 0.9922 - val_loss: 1.2215 - val_accuracy: 0.6992\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.1089 - accuracy: 0.9902 - val_loss: 1.2081 - val_accuracy: 0.7293\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.0956 - accuracy: 0.9902 - val_loss: 1.1640 - val_accuracy: 0.7368\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.0813 - accuracy: 0.9956 - val_loss: 1.2082 - val_accuracy: 0.7030\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0725 - accuracy: 0.9966 - val_loss: 1.1627 - val_accuracy: 0.7105\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0658 - accuracy: 0.9966 - val_loss: 1.1615 - val_accuracy: 0.7331\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.0601 - accuracy: 0.9985 - val_loss: 1.1142 - val_accuracy: 0.7331\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 92ms/step - loss: 0.0526 - accuracy: 0.9985 - val_loss: 1.1541 - val_accuracy: 0.7368\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 0.0509 - accuracy: 0.9990 - val_loss: 1.1551 - val_accuracy: 0.7406\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 96ms/step - loss: 0.0514 - accuracy: 0.9961 - val_loss: 1.1809 - val_accuracy: 0.7368\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0443 - accuracy: 0.9985 - val_loss: 1.1490 - val_accuracy: 0.7331\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.0402 - accuracy: 0.9995 - val_loss: 1.1534 - val_accuracy: 0.7406\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.0360 - accuracy: 0.9995 - val_loss: 1.1275 - val_accuracy: 0.7556\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 92ms/step - loss: 0.0354 - accuracy: 0.9985 - val_loss: 1.1929 - val_accuracy: 0.7368\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.0323 - accuracy: 0.9990 - val_loss: 1.1143 - val_accuracy: 0.7556\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.7632\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.7556\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.7594\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.0240 - accuracy: 0.9990 - val_loss: 1.1372 - val_accuracy: 0.7594\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.7444\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1869 - val_accuracy: 0.7519\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.0210 - accuracy: 0.9990 - val_loss: 1.1346 - val_accuracy: 0.7594\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 0.0197 - accuracy: 0.9995 - val_loss: 1.1552 - val_accuracy: 0.7519\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0190 - accuracy: 0.9995 - val_loss: 1.1679 - val_accuracy: 0.7406\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.0199 - accuracy: 0.9990 - val_loss: 1.2053 - val_accuracy: 0.7519\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 87ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.7519\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.7594\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.7632\n",
      "CNN Error: 23.68%\n"
     ]
    }
   ],
   "source": [
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 48, 40, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 48, 40, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(48, 40, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 14s 45ms/step - loss: 0.3737 - accuracy: 0.8841 - val_loss: 0.0930 - val_accuracy: 0.9690\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 13s 45ms/step - loss: 0.0969 - accuracy: 0.9699 - val_loss: 0.0496 - val_accuracy: 0.9841\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 14s 46ms/step - loss: 0.0692 - accuracy: 0.9784 - val_loss: 0.0402 - val_accuracy: 0.9862\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 14s 47ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.0343 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 14s 47ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.0325 - val_accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 14s 47ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.0354 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 14s 48ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.0271 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 15s 50ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0290 - val_accuracy: 0.9893\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 15s 49ms/step - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0256 - val_accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 14s 47ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.0238 - val_accuracy: 0.9906\n",
      "Large CNN Error: 0.94%\n"
     ]
    }
   ],
   "source": [
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
