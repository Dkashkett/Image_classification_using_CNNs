{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Neural Networks for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data chunks and converts to numpy arrays\n",
    "def load_pose_data():\n",
    "    pose = np.array(loadmat('./data/pose.mat')['pose'])\n",
    "    illum = np.array(loadmat('./data/illumination.mat')['illum'])\n",
    "    return pose, illum\n",
    "\n",
    "def make_pose_dataset(pose, illum, test_size = .3):\n",
    "    pose_data = []\n",
    "    pose_labels = []\n",
    "    for subject in range(68):\n",
    "        for img in range(13):\n",
    "            pose_data.append(pose[:,:,img,subject])\n",
    "            pose_labels.append(subject)\n",
    "            \n",
    "    pose_data = np.array(pose_data)\n",
    "    pose_labels = np.transpose(np.array(pose_labels))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(pose_data, pose_labels, test_size=test_size, random_state=31, stratify=pose_labels)\n",
    "    X_train, y_train = list(X_train), list(y_train)\n",
    "    \n",
    "    for subject in range(68):\n",
    "        for img in range(21):\n",
    "            image = illum[:,img,subject].reshape((40,48))\n",
    "            image = np.flip(np.rot90(image))\n",
    "            X_train.append(image)\n",
    "            y_train.append(subject)\n",
    "            \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks\n",
    "##### Below are functions to create the three neural networks architectures that I will be testing. The first is a very simple, shallow sequential NN, the second is a CNN, and the third is a deeper CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networks\n",
    "def build_sequential(num_classes):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn(input_shape):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_large_cnn(input_shape):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(input_shape), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSE Dataset\n",
    "##### I will first test these architectures on the POSE data from project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pose data\n",
    "pose, illum = load_pose_data()\n",
    "X_train, X_test, y_train, y_test = make_pose_dataset(pose, illum)\n",
    "\n",
    "#expand dimension to include number channels\n",
    "X_train = X_train.reshape((X_train.shape[0], 48, 40, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 48, 40, 1)).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "#flattened versions of data for sequentail model\n",
    "X_train_flat = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view pose data\n",
    "imgs = X_train[:4].reshape((4,48,40))\n",
    "plt.subplot(221)\n",
    "plt.imshow(imgs[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(imgs[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(imgs[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(imgs[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 - 0s - loss: 6.4104 - accuracy: 0.0249 - val_loss: 7.0308 - val_accuracy: 0.0226\n",
      "Epoch 2/10\n",
      "11/11 - 0s - loss: 5.2374 - accuracy: 0.0748 - val_loss: 4.7197 - val_accuracy: 0.1128\n",
      "Epoch 3/10\n",
      "11/11 - 0s - loss: 3.9267 - accuracy: 0.1891 - val_loss: 3.9123 - val_accuracy: 0.1429\n",
      "Epoch 4/10\n",
      "11/11 - 0s - loss: 3.2305 - accuracy: 0.3490 - val_loss: 3.5258 - val_accuracy: 0.1654\n",
      "Epoch 5/10\n",
      "11/11 - 0s - loss: 2.7120 - accuracy: 0.4795 - val_loss: 3.1213 - val_accuracy: 0.2932\n",
      "Epoch 6/10\n",
      "11/11 - 0s - loss: 2.3559 - accuracy: 0.5836 - val_loss: 3.1808 - val_accuracy: 0.2293\n",
      "Epoch 7/10\n",
      "11/11 - 0s - loss: 2.0525 - accuracy: 0.6549 - val_loss: 2.8197 - val_accuracy: 0.2932\n",
      "Epoch 8/10\n",
      "11/11 - 0s - loss: 1.7480 - accuracy: 0.7322 - val_loss: 2.5791 - val_accuracy: 0.3496\n",
      "Epoch 9/10\n",
      "11/11 - 0s - loss: 1.5703 - accuracy: 0.7522 - val_loss: 2.4999 - val_accuracy: 0.4286\n",
      "Epoch 10/10\n",
      "11/11 - 0s - loss: 1.3010 - accuracy: 0.8196 - val_loss: 2.3143 - val_accuracy: 0.4248\n",
      "Baseline Error: 57.52%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "pose_sequential = build_sequential(num_classes)\n",
    "# Fit the model\n",
    "pose_sequential.fit(X_train_flat, y_train, validation_data=(X_test_flat, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = pose_sequential.evaluate(X_test_flat, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],X_train.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 4.2154 - accuracy: 0.0308 - val_loss: 4.1510 - val_accuracy: 0.0677\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 4.0216 - accuracy: 0.1197 - val_loss: 4.0080 - val_accuracy: 0.0338\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 3.7119 - accuracy: 0.1691 - val_loss: 3.6689 - val_accuracy: 0.1466\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 3.2112 - accuracy: 0.3490 - val_loss: 3.3631 - val_accuracy: 0.1767\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 2.6585 - accuracy: 0.4927 - val_loss: 3.1571 - val_accuracy: 0.1805\n",
      "CNN Error: 81.95%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "pose_cnn = build_cnn(input_shape)\n",
    "# Fit the model\n",
    "pose_cnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = pose_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 4.2228 - accuracy: 0.0132 - val_loss: 4.2162 - val_accuracy: 0.0150\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 4.2137 - accuracy: 0.0225 - val_loss: 4.2074 - val_accuracy: 0.0113\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 4.1995 - accuracy: 0.0249 - val_loss: 4.1884 - val_accuracy: 0.0226\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 4.1658 - accuracy: 0.0279 - val_loss: 4.1228 - val_accuracy: 0.0263\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 1s 93ms/step - loss: 4.0689 - accuracy: 0.0450 - val_loss: 3.9931 - val_accuracy: 0.0301\n",
      "Large CNN Error: 96.99%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "large_cnn = build_large_cnn(input_shape)\n",
    "# Fit the model\n",
    "large_cnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = large_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view mnist data\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to include number channels\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "\n",
    "#flattened versions of data for sequentail model\n",
    "X_train_flat = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Sequential Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 - 0s - loss: 6.2141 - accuracy: 0.0293 - val_loss: 5.7686 - val_accuracy: 0.0301\n",
      "Epoch 2/10\n",
      "11/11 - 0s - loss: 4.5497 - accuracy: 0.1022 - val_loss: 4.0825 - val_accuracy: 0.0902\n",
      "Epoch 3/10\n",
      "11/11 - 0s - loss: 3.4987 - accuracy: 0.2199 - val_loss: 3.5931 - val_accuracy: 0.1579\n",
      "Epoch 4/10\n",
      "11/11 - 0s - loss: 3.0485 - accuracy: 0.3568 - val_loss: 3.5516 - val_accuracy: 0.0977\n",
      "Epoch 5/10\n",
      "11/11 - 0s - loss: 2.6345 - accuracy: 0.4780 - val_loss: 3.1489 - val_accuracy: 0.2556\n",
      "Epoch 6/10\n",
      "11/11 - 0s - loss: 2.2452 - accuracy: 0.5968 - val_loss: 2.8484 - val_accuracy: 0.3571\n",
      "Epoch 7/10\n",
      "11/11 - 0s - loss: 1.9214 - accuracy: 0.6745 - val_loss: 2.7247 - val_accuracy: 0.3609\n",
      "Epoch 8/10\n",
      "11/11 - 0s - loss: 1.6413 - accuracy: 0.7449 - val_loss: 2.5344 - val_accuracy: 0.4060\n",
      "Epoch 9/10\n",
      "11/11 - 0s - loss: 1.4040 - accuracy: 0.8021 - val_loss: 2.4427 - val_accuracy: 0.3722\n",
      "Epoch 10/10\n",
      "11/11 - 0s - loss: 1.2495 - accuracy: 0.8216 - val_loss: 2.3095 - val_accuracy: 0.4323\n",
      "Baseline Error: 56.77%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "mnist_sequential = build_sequential(num_classes)\n",
    "# Fit the model\n",
    "mnist_sequential.fit(X_train_flat, y_train, validation_data=(X_test_flat, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = mnist_sequential.evaluate(X_test_flat, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],X_train.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 9s 30ms/step - loss: 0.2419 - accuracy: 0.9292 - val_loss: 0.0821 - val_accuracy: 0.9743\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 9s 30ms/step - loss: 0.0753 - accuracy: 0.9780 - val_loss: 0.0497 - val_accuracy: 0.9840\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 9s 29ms/step - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.0430 - val_accuracy: 0.9861\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 9s 29ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0359 - val_accuracy: 0.9882\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 9s 30ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.0334 - val_accuracy: 0.9893\n",
      "CNN Error: 1.07%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "mnist_cnn = build_cnn(input_shape)\n",
    "# Fit the model\n",
    "mnist_cnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = mnist_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "300/300 [==============================] - 13s 44ms/step - loss: 0.3968 - accuracy: 0.8780 - val_loss: 0.0830 - val_accuracy: 0.9760\n",
      "Epoch 2/2\n",
      "300/300 [==============================] - 13s 43ms/step - loss: 0.0981 - accuracy: 0.9700 - val_loss: 0.0491 - val_accuracy: 0.9834\n",
      "Large CNN Error: 1.66%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "mnist_large_cnn = build_large_cnn(input_shape)\n",
    "# Fit the model\n",
    "mnist_large_cnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = mnist_large_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
